{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de140819-4ff6-44a3-bd53-737a5ee2d151",
   "metadata": {},
   "source": [
    "## 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0021df3-1669-417d-9d79-8f76e7a03210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1d628-3407-4cc5-ab86-15e2f8737d90",
   "metadata": {},
   "source": [
    "## 2. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3892e894-675d-41b8-99c0-e0345cfb1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Language Detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3cdfcd-5cce-4060-9171-719f8c6163da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nature, in the broadest sense, is the natural...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Nature\" can refer to the phenomena of the phy...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The study of nature is a large, if not the onl...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Although humans are part of nature, human acti...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1] The word nature is borrowed from the Old F...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Language\n",
       "0   Nature, in the broadest sense, is the natural...  English\n",
       "1  \"Nature\" can refer to the phenomena of the phy...  English\n",
       "2  The study of nature is a large, if not the onl...  English\n",
       "3  Although humans are part of nature, human acti...  English\n",
       "4  [1] The word nature is borrowed from the Old F...  English"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf88b61f-138b-44ef-96ec-a38212e4e774",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5fa291-c2a7-46ec-abf9-b15ca2cf078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"Text\"]\n",
    "y = data[\"Language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c055fb-4e2f-4d7b-9827-2e9d7e0ea3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f795bc-c117-405c-bb64-ce9838eab667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabic', 'Danish', 'Dutch', 'English', 'French', 'German',\n",
       "       'Greek', 'Hindi', 'Italian', 'Kannada', 'Malayalam', 'Portugeese',\n",
       "       'Russian', 'Spanish', 'Sweedish', 'Tamil', 'Turkish'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02655e0e-f8e7-4821-b846-c076261d2257",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for text in X:\n",
    "    text = re.sub(r'[!@#$(),\\n\"%^*?\\:;~`0-9]', ' ', text)\n",
    "    text = re.sub(r'[[]]', ' ', text)\n",
    "    text = text.lower()\n",
    "    data_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb102a82-aee5-46dd-abf9-9634f6e82c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96508242-fa60-4dca-b610-58dba25751f5",
   "metadata": {},
   "source": [
    "## 4. Performing NLP (creating bag of words using countvectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a65881-b34c-46da-be5d-63b0be0d64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv.fit(X_train)\n",
    "\n",
    "x_train = cv.transform(X_train).toarray()\n",
    "x_test  = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3722d9-3fc6-4691-beb3-a0770d3bd8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ecaa54e-c0dc-4188-9da8-1721d86d89fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a446d2-a926-4d95-822e-21c2952e9ca5",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b9b3626-f43e-4cd4-a33d-75686e37f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cr = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e014c0-5269-409a-8c19-3dcff7eeabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9753384912959381\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is :\",ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79f8cec-3c3c-4ab7-87a7-fa3988453b03",
   "metadata": {},
   "source": [
    "Learn more about sklearn pipeline from: https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3baead9-8aaf-4911-ae1d-e5edf472d75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('multinomialNB', MultinomialNB())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([('vectorizer', cv), ('multinomialNB', model)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d562185-fc8a-43b9-9cbc-433be79bc1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9753384912959381\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = pipe.predict(X_test)\n",
    "ac2 = accuracy_score(y_test, y_pred2)\n",
    "print(\"Accuracy is :\",ac2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df30ba04-8194-4d38-932d-74b183d7fb42",
   "metadata": {},
   "source": [
    "## 6. Saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4c3b9ff-bf83-4fc0-ba6c-d7b00c7e0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trained_pipeline-0.1.0.pkl','wb') as f:\n",
    "    pickle.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e221809-9664-4920-9114-f73f03756591",
   "metadata": {},
   "source": [
    "## 7. Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4705979-c7b5-4065-a8b6-65c8dc933966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('French', array([4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = \"Hello, how are you?\"\n",
    "text = \"salut comment vas-tu\"\n",
    "\n",
    "y = pipe.predict([text])\n",
    "le.classes_[y[0]], y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc193dca-42ba-4613-8d54-f090d286c7e8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we have successfully developed an Language Detection ML model that addressed the fundamental challenge of identifying the language of \n",
    "text data ('Arabic', 'Danish', 'Dutch', 'English', 'French', 'German', 'Greek', 'Hindi', 'Italian', 'Kannada', 'Malayalam', Portuguesee', 'Russian', 'Spanish', 'Sweedish', 'Tamil', 'Turkish'). Through a combination of robust data preprocessing, feature extraction,\n",
    "and machine learning techniques, we have developed a reliable and accurate language detection system.\n",
    "\n",
    "## References:\n",
    "[1] Aaron Jaech, George Mulcaire, Shobhit Hathi, Mari Ostendor, Noah A. Smith: \"Hierarchical Character-Word Models for\n",
    "Language Identification\" (Aug 2016).\n",
    "\n",
    "[2] Priyank Mathur, Arkajyoti Misra, Emrah Budur: \"Language Identification from Text Documents\" (2015).\n",
    "\n",
    "[3] Shashank Simha B K, Rahul M, Jyoti R Munavalli, Prajwal Anand: \"Dual-Language Detection using Machine Learning\"\n",
    "(Dec 2022).\n",
    "\n",
    "[4] Sowmya Vajjala, Sagnik Banerjee: \"A study of N-gram and Embedding Representations for Native Language Identification\"\n",
    "(September 8, 2017).\n",
    "\n",
    "[5] Adarsh.D.Patil, Akshay Vishwas Joshi, Harsha. K.C, Pramod. N: \"Spoken Language Identification Using Machine Learning\"\n",
    "(May 2012).\n",
    "\n",
    "[6] Marco Lui, Jey Han Lau, Timothy Baldwin: \"Automatic Detection and Language Identification of Multilingual Documents\"\n",
    "(Feb 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a911b9d-7329-4414-92b7-86b8b3eaefa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALDenv",
   "language": "python",
   "name": "aldenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
